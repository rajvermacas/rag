Brainstorm.
I am trying to build a RAG pipeline.
Openrouter should be used.

A UI should be built using tailwind css, fastapi.
There should be a file upload button which should read files like pdf, docx, text.

And then there should be a chatbot which should help talk to the doc.
-----------------------------------

Right now the chatbot clearly mentions that "I dont know" if the user prompt is generic. 
I want the chatbot to intelligently say that This is what i found over the document as per the citation and here is what i know (coming from general training)
-----------------------------------

There are couple of things which needs to be fixed/implemented:
1. The UI looks very dull. It should be flulid and interactive.
2. The UI should follow the color combination Red, Gray, Black and White
3. In new tab or section which can be navigated: The UI should show all the files already uploaded
4. It should also have option to delete the file so that the indexing is also deleted of course
5. The chatbot should be aware about all the documents that have been uploaded. and if asked about questions like what all documents you have access to then it should clearly share the names of the documents uploaded.
6. The chat reponse on the UI doesn't look like markdown formatted text. It's plain raw text wher ** are even visible and doesn't look like a professional app altogether.
7. Citations always shows something like `Citations: .txt#0` even if the response contains the text from the document uploaded.
8. Fix the citations and it should be interactive in a way that clicking on the citation should quickly show the exact text from the document
9. There is a bug. running below command it gives not found error:
npm run build:css

> rag-openrouter-ui@0.1.0 build:css
> tailwindcss -i ./app/static/css/input.css -o ./app/static/css/output.css --minify

sh: 1: tailwindcss: not found
--------------------------

There are couple of things which needs to be fixed/implemented:
1. There should be a clear chat option along with chat history to choose from a drop down.
2. There should be no gradient style on the UI.
3. Do not show citations on the UI
4. User message should be at the right side of the chat bot and chatbot response should be on the left side.
5. Add a loader in the Upload and index button
6. Change the Upload and index button name to just Upload
7. After a document is indexed just show after the loader that upload successful
----------------------------

There are couple of things which needs to be fixed/implemented:
1. When a question is asked to the chatbot, the response doesn't stream.
2. Therre is no thinking... when the chatbot response is awaited making it difficult for the end user if the app is stuck or what?
3. The Upload successful is a text which looks ugly. Design it properly
4. Once the upload starts there is already a loader so no need to explictly write it down below in text Uploading document.
5. Instead of having Clear Chat make it New Chat
6. I see these texts [nitin.pdf#chunk_id=0, nitin.pdf#chunk_id=3] in the chatbot response. I don't need citations.
----------------------------

There are couple of things which needs to be fixed/implemented:
1. Remove the text from the UI that says: Palette: Red, Gray, Black, White
2. Once the app restats all the saved chats are wiped out. It should be persisted properly.
3. There should be no Documents tab. Documents shoulld be visible just below the Upload button with filename and delete button.

----------------------------

There are couple of things which needs to be fixed/implemented:
1. On the Chat page and battlegroup page, user message should appear on right and assistant message should appear on left. Right now both the messages start appear on the left side.

There are couple of things which needs to be fixed/implemented:
1. The chat section should also have a drop down for model selection
-----------------------------------

There are couple of things which needs to be fixed/implemented:
1. At the end of the chatbot response of battleground chat. There is always a word `Done` at the end of the response. Debug and fix the issue.
-----------------------------------

There are couple of things which needs to be fixed/implemented:
1. Why is there hardcoded values in llm_registry.py
_PROVIDER_OPENROUTER = "openrouter"
_PROVIDER_OPENAI = "openai"
_PROVIDER_AZURE_OPENAI = "azure_openai"
_OPENROUTER_API_BASE_URL = "https://openrouter.ai/api/v1"

2. check carefully what exactly is really needed in .env.example I can see stale vars not being referred anywhere in the code. Fix it.

3. First chat takes a lot of time to get the response. From second message it works fine. Why don't you update to handle the heavy initialisation part at the time of service startup only. so that from the first msg itslef it seems fast.
For your context, here is a log which always gets printed when the first message is taking time:
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.

4. Clicking on The input box in the chatbot suggests my previous messages in a box on browser maybe on the HTML layer. please remove it.

5. When the document is not uploaded Even for a hi message to the chatbot I receive `I could not generate a response from the current context. Please rephrase your question.`

When the document is not present then also the chatbot should be able to chat as it is connect to LLM, it seems that there is somewhere a
hard dependncy on the document and if the document is not found maybe the request is never sent to the LLM or so. Debug the issue and find
the root cause